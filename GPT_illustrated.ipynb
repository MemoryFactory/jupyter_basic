{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9454d2cf-64de-4f66-8f90-ecae70e62740",
   "metadata": {},
   "source": [
    "# 《GPT图解 大模型是怎样构建的》"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20773b-6b57-456f-b04e-8abe61d8092e",
   "metadata": {},
   "source": [
    "### 1.3 创建一个Bigram字符预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf4da710-7eba-4253-8f03-375e556c40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个玩具数据集\n",
    "corpus = ['我喜欢吃苹果',\n",
    "          '我喜欢吃香蕉',\n",
    "          '她喜欢吃葡萄',\n",
    "          '他不喜欢吃香蕉',\n",
    "          '他喜欢吃苹果',\n",
    "          '她喜欢吃草莓',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fc32714-3768-4e3c-acd8-f1b10e429217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个分词函数，将文本转换为单个字符的列表\n",
    "def tokenize(text):\n",
    "    return [char for char in text] # 将文本拆分为字符列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3d4b6bd-dfb6-4e9a-a40f-23213785e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram词频：\n",
      "我: {'喜': 2}\n",
      "喜: {'欢': 6}\n",
      "欢: {'吃': 6}\n",
      "吃: {'苹': 2, '香': 2, '葡': 1, '草': 1}\n",
      "苹: {'果': 2}\n",
      "香: {'蕉': 2}\n",
      "她: {'喜': 2}\n",
      "葡: {'萄': 1}\n",
      "他: {'不': 1, '喜': 1}\n",
      "不: {'喜': 1}\n",
      "草: {'莓': 1}\n"
     ]
    }
   ],
   "source": [
    "# 定义计算N-Gram词频的函数\n",
    "from collections import defaultdict, Counter \n",
    "\n",
    "def count_ngrams(corpus, n):\n",
    "    ngrams_count = defaultdict(Counter) # 创建一个字典，存储N-Gram计数\n",
    "    for text in corpus: # 遍历语料库中的每个文本\n",
    "        tokens = tokenize(text) # 对文本进行分词\n",
    "        for i in range(len(tokens)-n+1): # 遍历分词结果，生成N-Gram\n",
    "            ngram = tuple(tokens[i:i+n]) # 创建一个N-Gram元组\n",
    "            prefix = ngram[:-1] # 获取N-Gram的前缀\n",
    "            token = ngram[-1] # 获取N-Gram的目标单字\n",
    "            ngrams_count[prefix][token] += 1 # 更新N-Gram计数 {(prefix,): Counter({token: n,})}\n",
    "    return ngrams_count\n",
    "\n",
    "bigram_counts = count_ngrams(corpus, 2) # 计算Bigram词频\n",
    "print('Bigram词频：')\n",
    "for prefix, counts in bigram_counts.items():\n",
    "    print(f'{\"\".join(prefix)}: {dict(counts)}')\n",
    "\n",
    "###\n",
    "# print(bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9f4933b-a37a-4b07-b191-77ad7ef2403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bigram出现的概率：\n",
      "我: {'喜': 1.0}\n",
      "喜: {'欢': 1.0}\n",
      "欢: {'吃': 1.0}\n",
      "吃: {'苹': 0.3333333333333333, '香': 0.3333333333333333, '葡': 0.16666666666666666, '草': 0.16666666666666666}\n",
      "苹: {'果': 1.0}\n",
      "香: {'蕉': 1.0}\n",
      "她: {'喜': 1.0}\n",
      "葡: {'萄': 1.0}\n",
      "他: {'不': 0.5, '喜': 0.5}\n",
      "不: {'喜': 1.0}\n",
      "草: {'莓': 1.0}\n",
      "defaultdict(<class 'collections.Counter'>, {('我',): Counter({'喜': 1.0}), ('喜',): Counter({'欢': 1.0}), ('欢',): Counter({'吃': 1.0}), ('吃',): Counter({'苹': 0.3333333333333333, '香': 0.3333333333333333, '葡': 0.16666666666666666, '草': 0.16666666666666666}), ('苹',): Counter({'果': 1.0}), ('香',): Counter({'蕉': 1.0}), ('她',): Counter({'喜': 1.0}), ('葡',): Counter({'萄': 1.0}), ('他',): Counter({'不': 0.5, '喜': 0.5}), ('不',): Counter({'喜': 1.0}), ('草',): Counter({'莓': 1.0})})\n"
     ]
    }
   ],
   "source": [
    "# 定义计算N-Gram出现概率的函数\n",
    "def ngram_probabilities(ngram_counts):\n",
    "    ngram_probs = defaultdict(Counter) # 创建一个字典，存储N-Gram出现的概率\n",
    "    for prefix, tokens_count in ngram_counts.items(): # 遍历N-Gram前缀\n",
    "        total_count = sum(tokens_count.values()) # 计算当前前缀的N-Gram计数\n",
    "        for token, count in tokens_count.items(): # 遍历每个前缀的N-Gram\n",
    "            ngram_probs[prefix][token] = count / total_count # 计算每个N-Gram出现的概率\n",
    "    return ngram_probs\n",
    "\n",
    "bigram_probs = ngram_probabilities(bigram_counts) # 计算Bigram出现的概率\n",
    "print('\\nbigram出现的概率：')\n",
    "for prefix, probs in bigram_probs.items():\n",
    "    print(f'{\"\".join(prefix)}: {dict(probs)}')\n",
    "\n",
    "###\n",
    "print(bigram_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "960d5959-f0d6-4d7e-bd30-449632f43582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成下一个词的函数\n",
    "def generate_next_token(prefix, ngram_probs):\n",
    "    if not prefix in ngram_probs:\n",
    "        return None\n",
    "    next_token_probs = ngram_probs[prefix] # 获取当前前缀的下一个词的概率\n",
    "    next_token = max(next_token_probs, key=next_token_probs.get) # 选择概率最大的词作为下一个词\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c2507db-7aaf-4458-88ed-ef64583027fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成连续文本的函数\n",
    "def generate_text(prefix, ngram_probs, n, length=6):\n",
    "    tokens = list(prefix)\n",
    "    for _ in range(length-len(prefix)): # 根据指定长度生成文本\n",
    "        next_token = generate_next_token(tuple(tokens[-(n-1):]), ngram_probs)\n",
    "        print(tokens)\n",
    "        print(tuple(tokens[-(n-1):]))\n",
    "        if not next_token:\n",
    "            break\n",
    "        tokens.append(next_token)\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a588f80-957c-43bf-812c-4bc27815fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我']\n",
      "('我',)\n",
      "['我', '喜']\n",
      "('喜',)\n",
      "['我', '喜', '欢']\n",
      "('欢',)\n",
      "['我', '喜', '欢', '吃']\n",
      "('吃',)\n",
      "['我', '喜', '欢', '吃', '苹']\n",
      "('苹',)\n",
      "\n",
      "生成的文本： 我喜欢吃苹果\n"
     ]
    }
   ],
   "source": [
    "# 输入一个前缀，生成文本\n",
    "generated_text = generate_text('我', bigram_probs, 2)\n",
    "print('\\n生成的文本：', generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
